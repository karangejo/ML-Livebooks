# Glass Type Classification

```elixir
Mix.install([
  {:axon, "~> 0.1.0"},
  {:exla, "~> 0.2.2"},
  {:nx, "~> 0.2.1"},
  {:explorer, "~> 0.2.0"},
  {:req, "~> 0.3.0"},
  {:vega_lite, "~> 0.1.5"},
  {:kino_vega_lite, "~> 0.1.1"}
])
```

## Introduction

In this notebook we are going to be exploring the Glass type dataset. This dataset is from the UCI repository. It was motivated by a criminal case where identification of a certain type of glass fragment was crucial. You can read more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/glass+identification)

First we will load the data into `Explorer` and take a look. Then we will use `Nx` to prepare our data for training and testing. Finally we will use `Axon` to build a Neural Network and train it with the dataset. Along the way we will plot some charts with `VegaLite`.

It is a multiclass classification problem with 7 classes labeled from 1 to 7. All the other input variables are numeric.

## Load the Dataset

First lets download the data to our machine and then load it into `Explorer`. We will append the column names to the csv so we can use them in the dataframe.

```elixir
%{body: body} =
  Req.get!("https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data")

filename = "glass_data.csv"
column_names = "id_number,RI,Na,Mg,Al,Si,K,Ca,Ba,Fe,class\n"

File.write!(filename, column_names <> body)

df = Explorer.DataFrame.from_csv!(filename)
```

Now we can explore the dataset to see what is inside

```elixir
Explorer.DataFrame.pull(df, "class")
|> Explorer.Series.distinct()
```

Looks like there are no instances of class 4! Lets build a look up table so we can get the names of the classes from the numbers.

```elixir
classes = %{
  1 => "building_windows_float_processed",
  2 => "building_windows_non_float_processed",
  3 => "vehicle_windows_float_processed",
  4 => "vehicle_windows_non_float_processed",
  5 => "containers",
  6 => "tableware",
  7 => "headlamps"
}
```

```elixir
Explorer.DataFrame.n_rows(df)
```

Let's calculate the mean of every column and plot it out.

```elixir
defmodule ReduceData do
  def reduce_df(data_frame, series_fun) do
    data_frame
    |> Explorer.DataFrame.to_series()
    |> Enum.map(fn {col_name, col} ->
      %{"x" => col_name, "y" => series_fun.(col)}
    end)
  end
end

mean_data =
  ReduceData.reduce_df(
    df
    |> Explorer.DataFrame.select(["id_number", "class"], :drop),
    &Explorer.Series.mean/1
  )
```

```elixir
VegaLite.new(width: 400, height: 400)
|> VegaLite.data_from_values(mean_data)
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "x", type: :nominal)
|> VegaLite.encode_field(:y, "y", type: :quantitative)
```

Now lets group the data by class and calculate the mean max and min value for each column

```elixir
class_grouped_df = Explorer.DataFrame.group_by(df, ["class"])
```

```elixir
cols = ["Al", "Ba", "Ca", "Fe", "K", "Mg", "Na", "RI", "Si"]

class_summary_df =
  Explorer.DataFrame.summarise(
    class_grouped_df,
    cols
    |> Enum.reduce(%{}, fn name, acc ->
      acc
      |> Map.put(name, [:min, :max, :mean])
    end)
  )
```

Nice! Now lets plot out the chart for each group with `VegaLite`

```elixir
vega_concats =
  class_summary_df
  |> Explorer.DataFrame.to_rows()
  |> Enum.map(fn row ->
    data =
      row
      |> Enum.map(fn {key, val} ->
        %{"x" => key, "y" => val}
      end)

    class_row =
      data
      |> Enum.find(fn row ->
        row["x"] == "class"
      end)

    class = classes[class_row["y"]]

    data =
      data
      |> Enum.reject(fn row ->
        row["x"] == "class"
      end)

    VegaLite.new(width: 700, height: 400, title: class)
    |> VegaLite.data_from_values(data)
    |> VegaLite.mark(:bar)
    |> VegaLite.encode_field(:x, "x", type: :nominal)
    |> VegaLite.encode_field(:y, "y", type: :quantitative)
  end)

VegaLite.new(width: 700)
|> VegaLite.concat(vega_concats, :vertical)
```

## Prepare the Data

Now we need to get our data ready for training. First we will normalize our data using the min-max scaling technique. This will transform every value in each column to be between 0 and 1 and will facilitate the training of our model.

```elixir
defmodule NormalData do
  def normalize(data_frame, col_names) do
    data_frame
    |> Explorer.DataFrame.select(col_names)
    |> Explorer.DataFrame.to_series()
    |> Enum.map(fn {col_name, col} ->
      max = Explorer.Series.max(col)
      min = Explorer.Series.min(col)
      range = max - min

      normalize_fun = fn val ->
        (val - min) / range
      end

      {col_name,
       Explorer.Series.subtract(col, min)
       |> Explorer.Series.cast(:float)
       |> Explorer.Series.divide(range), normalize_fun}
    end)
  end
end
```

```elixir
normal =
  NormalData.normalize(
    df,
    ["Al", "Ba", "Ca", "Fe", "K", "Mg", "Na", "RI", "Si"]
  )

normal_df =
  normal
  |> Enum.map(fn {col_name, normalized_data, _normalize_fun} ->
    {col_name, normalized_data}
  end)
  |> Explorer.DataFrame.new()
  |> Explorer.DataFrame.mutate(id_number: Explorer.DataFrame.pull(df, "id_number"))
  |> Explorer.DataFrame.mutate(class: Explorer.DataFrame.pull(df, "class"))

normalize_row_fun = fn row ->
  normalize_funs =
    normal
    |> Enum.filter(fn {col_name, _, _} ->
      col_name in [
        "Al",
        "Ba",
        "Ca",
        "Fe",
        "K",
        "Mg",
        "Na",
        "RI",
        "Si"
      ]
    end)
    |> Enum.map(fn {_, _, normalize_fun} ->
      normalize_fun
    end)

  Enum.zip([normalize_funs, Nx.to_flat_list(row)])
  |> Enum.map(fn {normalize_fun, elem} ->
    normalize_fun.(elem)
  end)
  |> Nx.tensor()
end
```

```elixir
mean_normal_data =
  ReduceData.reduce_df(
    normal_df
    |> Explorer.DataFrame.select(["id_number", "class"], :drop),
    &Explorer.Series.mean/1
  )
```

```elixir
VegaLite.new(width: 400, height: 400)
|> VegaLite.data_from_values(mean_normal_data)
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "x", type: :nominal)
|> VegaLite.encode_field(:y, "y", type: :quantitative)
```

```elixir
defmodule SplitData do
  def train_test_split(data_frame, train_percentage) do
    series = Explorer.DataFrame.pull(data_frame, "id_number")

    train_sample =
      series
      |> Explorer.Series.sample(train_percentage)
      |> Explorer.Series.to_list()
      |> Enum.sort()

    test_sample_df =
      series
      |> Explorer.Series.to_list()
      |> Kernel.--(train_sample)
      |> Enum.sort()
      |> Kernel.then(fn list ->
        Explorer.DataFrame.new(id_number: list)
      end)

    train_sample_df = Explorer.DataFrame.new(id_number: train_sample)

    {Explorer.DataFrame.join(train_sample_df, data_frame),
     Explorer.DataFrame.join(test_sample_df, data_frame)}
  end
end
```

```elixir
{train_df, test_df} = SplitData.train_test_split(normal_df, 0.75)
```

```elixir
defmodule Convert do
  def to_training_data(df, col_names) do
    col_names
    |> Enum.map(fn name ->
      df[name]
      |> Explorer.Series.to_tensor(names: [name])
      |> Nx.reshape({:auto, 1})
    end)
    |> Nx.concatenate(axis: 1)
  end

  def one_hot_encode(outputs) do
    outputs
    |> Nx.equal(Nx.tensor(Enum.to_list(1..7)))
  end
end
```

```elixir
train_input_data =
  train_df
  |> Convert.to_training_data(["Al", "Ba", "Ca", "Fe", "K", "Mg", "Na", "RI", "Si"])
  |> Nx.to_batched_list(32)

train_output_data =
  train_df
  |> Convert.to_training_data(["class"])
  |> Convert.one_hot_encode()
  |> Nx.to_batched_list(32)

test_input_data =
  test_df
  |> Convert.to_training_data(["Al", "Ba", "Ca", "Fe", "K", "Mg", "Na", "RI", "Si"])

test_output_data =
  test_df
  |> Convert.to_training_data(["class"])
  |> Convert.one_hot_encode()
```

```elixir
train_input_data
|> List.first()
|> IO.inspect()
|> Nx.to_heatmap()
```

```elixir
model =
  Axon.input({nil, 9}, "input")
  |> Axon.dense(128, activation: :relu)
  |> Axon.dropout(rate: 0.2)
  |> Axon.dense(128, activation: :relu)
  |> Axon.dropout(rate: 0.1)
  |> Axon.dense(7, activation: :softmax)
```

```elixir
params =
  model
  |> Axon.Loop.trainer(:categorical_cross_entropy, :adam)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.metric(:precision)
  |> Axon.Loop.run(Stream.zip(train_input_data, train_output_data), %{},
    compiler: EXLA,
    epochs: 2000
  )
```

```elixir
%{prediction: prediction} = Axon.predict(model, params, test_input_data, mode: :train)
```

```elixir
Axon.Metrics.accuracy(test_output_data, prediction)
```

```elixir
defmodule Confusion do
  def matrix(output, pred) do
    true_pos = Axon.Metrics.true_positives(output, pred) |> Nx.to_number()
    true_neg = Axon.Metrics.true_negatives(output, pred) |> Nx.to_number()
    false_pos = Axon.Metrics.false_positives(output, pred) |> Nx.to_number()
    false_neg = Axon.Metrics.false_negatives(output, pred) |> Nx.to_number()

    [
      %{"predicted" => "true", "ground truth" => "true", "val" => true_pos},
      %{"predicted" => "false", "ground truth" => "false", "val" => true_neg},
      %{"predicted" => "true", "ground truth" => "false", "val" => false_pos},
      %{"predicted" => "false", "ground truth" => "true", "val" => false_neg}
    ]
  end
end
```

```elixir
confusion_matrix_data = Confusion.matrix(test_output_data, prediction)
```

```elixir
VegaLite.new(width: 400, height: 400)
|> VegaLite.data_from_values(confusion_matrix_data)
|> VegaLite.encode_field(:x, "predicted", type: :nominal)
|> VegaLite.encode_field(:y, "ground truth", type: :nominal)
|> VegaLite.layers([
  VegaLite.new()
  |> VegaLite.mark(:rect)
  |> VegaLite.encode_field(:color, "val", type: :quantitative),
  VegaLite.new()
  |> VegaLite.mark(:text)
  |> VegaLite.encode_field(:text, "val", type: :quantitative)
])
```

```elixir
test_output_data_list =
  test_output_data
  |> Nx.to_batched_list(1)

test_input_data_list =
  test_input_data
  |> Nx.to_batched_list(1)

vega_concats =
  Enum.zip(test_output_data_list, test_input_data_list)
  |> Enum.group_by(fn {output, _input} ->
    output
    |> Nx.argmax()
    |> Nx.to_number()
    |> Kernel.+(1)
  end)
  |> Enum.map(fn {class, data} ->
    glass_type = classes[class]

    {out, inp} = Enum.unzip(data)

    outputs =
      out
      |> Enum.map(&Nx.to_flat_list/1)
      |> Nx.tensor()

    inputs =
      inp
      |> Enum.map(&Nx.to_flat_list/1)
      |> Nx.tensor()

    %{prediction: pred} = Axon.predict(model, params, inputs, mode: :train)
    conf_matrix_data = Confusion.matrix(outputs, pred)

    VegaLite.new(width: 400, height: 400)
    |> VegaLite.data_from_values(conf_matrix_data)
    |> VegaLite.encode_field(:x, "predicted", type: :nominal)
    |> VegaLite.encode_field(:y, "ground truth", type: :nominal)
    |> VegaLite.layers([
      VegaLite.new(title: glass_type)
      |> VegaLite.mark(:rect)
      |> VegaLite.encode_field(:color, "val", type: :quantitative),
      VegaLite.new()
      |> VegaLite.mark(:text)
      |> VegaLite.encode_field(:text, "val", type: :quantitative)
    ])
  end)

VegaLite.new(width: 800)
|> VegaLite.concat(vega_concats, :vertical)
```

```elixir
pr_data =
  [
    %{
      "name" => "precision",
      "val" => Axon.Metrics.precision(test_output_data, prediction) |> Nx.to_number()
    },
    %{
      "name" => "recall",
      "val" => Axon.Metrics.recall(test_output_data, prediction) |> Nx.to_number()
    }
  ]
  |> IO.inspect()

VegaLite.new(width: 400, height: 400)
|> VegaLite.data_from_values(pr_data)
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "name", type: :nominal)
|> VegaLite.encode_field(:y, "val", type: :quantitative)
```
